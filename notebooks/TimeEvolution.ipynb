{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time evolution of `starry` maps"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    This tutorial showcases some experimental features. Modeling time evolution in ``starry`` is\n",
    "    still quite clunky and inefficient. It is also **extremely difficult!** Whatever degeneracies\n",
    "    we have in the static case (there are tons!) are made even worse by the fact that we now have\n",
    "    many more degrees of freedom. Unless we have really good priors, it is very difficult to get meaningful\n",
    "    results out of time-variable maps. We're working on ways to make this easier, faster, and more\n",
    "    tractable, so please stay tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we're going to take a look at how to model a star whose light curve evolves in time. The assumption here is that the evolution is due to either spot migration / evolution or differential rotation, so we need a way to model a time-variable surface map. There's a few different ways we can do that. Please note that these are all **experimental features** -- we're still working on the most efficient way of modeling temporal variability, so stay tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "%run notebook_setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with our usual imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.special import factorial\n",
    "import starry\n",
    "\n",
    "starry.config.lazy = False\n",
    "starry.config.quiet = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a map with three discrete Gaussian spots at different latitudes, rotating at slightly different rates due to a differential rotation with small shear $\\alpha = 0.02$. To create this dataset, we are linearly combining the flux generated from three separate maps and median-normalizing the light curve at the end.\n",
    "\n",
    "We're giving the map an inclination of 60 degrees and some limb darkening. These choices reduce the size of the null space slightly, making it easier to do inference. (Note that we are cheating since we assume below that we know the inclination and limb darkening exactly!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc = 60  # inclination\n",
    "u1 = 0.5  # linear limb darkening coeff\n",
    "alpha = 0.02  # differential rotation shear\n",
    "P = 1.0  # equatorial period\n",
    "intensity = -0.5  # spot intensity\n",
    "sigma = 0.05  # spot size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 10th degree map with linear limb darkening\n",
    "np.random.seed(0)\n",
    "map = starry.Map(10, 1)\n",
    "map[1] = u1\n",
    "omega_eq = 360.0 / P\n",
    "time = np.linspace(0, 30, 1000)\n",
    "time_ani = time[::10]\n",
    "true_flux = np.zeros_like(time)\n",
    "res = 300\n",
    "true_image_rect = np.zeros((len(time_ani), res, res))\n",
    "true_image_ortho = np.zeros((len(time), res, res))\n",
    "\n",
    "# Generate light curves for three spots\n",
    "true_lats = [-30, 30, -20]\n",
    "true_lons = [-90, 60, 135]\n",
    "for lat, lon in zip(true_lats, true_lons):\n",
    "\n",
    "    # The angular velocity at the current latitude, computed\n",
    "    # from the equation for linear differential rotation\n",
    "    omega = omega_eq * (1 - alpha * np.sin(lat * np.pi / 180.0) ** 2)\n",
    "\n",
    "    # Reset the map coefficients & add a new spot\n",
    "    map.reset()\n",
    "    map.inc = inc\n",
    "    map[1] = u1\n",
    "    map.add_spot(intensity=intensity, sigma=sigma, lat=lat, lon=lon)\n",
    "\n",
    "    # Add to the flux\n",
    "    true_flux += map.flux(theta=omega * time)\n",
    "\n",
    "    # Add to our sky-prjected image\n",
    "    true_image_ortho += map.render(theta=omega * time)\n",
    "\n",
    "    # Hack: to get our lat-lon image, we need to manually\n",
    "    # shift the image of each spot according to how far it\n",
    "    # has lagged due to differential rotation. Sorry --\n",
    "    # there's no easy way to do this in starry currently!\n",
    "    tmp = map.render(projection=\"rect\")\n",
    "    shift = np.array((omega - omega_eq) * time_ani * res / 360, dtype=int)\n",
    "    for n in range(len(time_ani)):\n",
    "        true_image_rect[n] += np.roll(tmp, shift[n], axis=1)\n",
    "\n",
    "# Normalize and add a little bit of noise\n",
    "flux_err = 1e-5\n",
    "flux = true_flux / np.nanmedian(true_flux)\n",
    "flux += flux_err * np.random.randn(len(time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the map by passing in the image arrays. Let's look at it in sky projection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map.show(image=true_image_ortho, projection=\"ortho\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and in lat-lon coordinates that co-rotate with the equator (note that limb darkening is disabled in this projection by default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map.show(image=true_image_rect, projection=\"rect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the light curve we're going to do inference on. You can tell there's some differential rotation because of the change in the morphology over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, true_flux / np.nanmedian(true_flux), \"C0-\", lw=1, alpha=0.5)\n",
    "plt.plot(time, flux, \"C0.\", ms=3)\n",
    "plt.gca().get_yaxis().get_major_formatter().set_useOffset(False)\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.ylabel(\"flux [normalized]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to model this with `starry`, so let's go over each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using a Taylor expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in `starry`, the flux is a linear function of the spherical harmonic coefficient vector:\n",
    "\n",
    "$$\n",
    "\\mathbf{f} = \\mathbf{A} \\mathbf{x}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{f}$ is the flux vector, $\\mathbf{A} = \\mathbf{A}(\\Theta)$ is the design matrix (a function of a bunch of parameters $\\Theta$) that transforms the map to a light curve, and\n",
    "\n",
    "$$\n",
    "\\mathbf{x} \\equiv a \\mathbf{y}\n",
    "$$\n",
    "\n",
    "is the vector of spherical harmonic coefficients $\\mathbf{y}$ weighted by the map amplitude $a$ (a value proportional to the luminosity of the map).\n",
    "If the map is time variable, we can express this by allowing $\\mathbf{x}$ to be a function of time: $\\mathbf{x} = \\mathbf{x}(t) = a(t) \\mathbf{y}(t)$. To make this tractable, we can Taylor expand this vector about $t=0$:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}(t) = \\mathbf{x}\\,\\Big|_{t=0} \\,\\,\\,+\\,\\,\\, \\mathbf{\\dot{x}}\\,\\Big|_{t=0}t \\,\\,\\,+\\,\\,\\, \\frac{1}{2}\\mathbf{\\ddot{x}}\\,\\Big|_{t=0}t^2 \\,\\,\\,+\\,\\,\\, ...\n",
    "$$\n",
    "\n",
    "The corresponding flux vector (i.e., the light curve) is then\n",
    "\n",
    "$$\n",
    "\\mathbf{f} = \\mathbf{A} \\mathbf{x}\\,\\Big|_{t=0} \\,\\,\\,+\\,\\,\\, \\mathbf{A} \\mathbf{\\dot{x}}\\,\\Big|_{t=0}t\n",
    "             \\,\\,\\,+\\,\\,\\, \\mathbf{A} \\frac{1}{2}\\mathbf{\\ddot{x}}\\,\\Big|_{t=0}t^2 \\,\\,\\,+\\,\\,\\, ...\n",
    "$$\n",
    "\n",
    "which we can write in matrix form as \n",
    "\n",
    "$$\n",
    "\\mathbf{f} = \\mathbf{A'} \\mathbf{x'}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\mathbf{A'} \\equiv \\Big( \\mathbf{A} \\quad \\mathbf{A} t \\quad \\frac{1}{2} \\mathbf{A} t^2 \\quad ... \\Big)\n",
    "$$\n",
    "\n",
    "is an augmented design matrix and\n",
    "\n",
    "$$\n",
    "\\mathbf{x'} = \\begin{pmatrix}\\mathbf{x} \\\\ \\mathbf{\\dot{x}} \\\\ \\mathbf{\\ddot{x}} \\\\ ...\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "is the vector of spherical harmonic coefficients and their derivatives.\n",
    "\n",
    "We can therefore *linearly solve* for the coefficients and their derivatives if we just augment the design matrix in this fashion (and provide suitable priors). Let's do that below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate a map. We'll solve for the map up to $l = 5$ only and go up to 4th derivatives in the Taylor expansion. Note that we are solving for $4 \\times (5 + 1)^2 = 144$ coefficients in total, so we'll need some good regularization to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = starry.Map(5, 1)\n",
    "map.inc = inc\n",
    "map[1] = u1\n",
    "order = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to build the augmented design matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the usual design matrix\n",
    "theta = 360.0 / P * time\n",
    "A0 = map.design_matrix(theta=theta)\n",
    "\n",
    "# Normalize and center the time array\n",
    "# (to help with numerical stability)\n",
    "t = 2.0 * (time / time[-1] - 0.5)\n",
    "\n",
    "# Horizontally stack the quantity 1/n! A0 t^n\n",
    "coeff = 1.0 / factorial(np.arange(order + 1))\n",
    "T = np.vander(t, order + 1, increasing=True) * coeff\n",
    "A = np.hstack([(A0 * T[:, n].reshape(-1, 1)) for n in range(order + 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what that looks like (the derivative orders are indicated):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A, aspect=\"auto\")\n",
    "[plt.axvline(n * map.Ny - 1, color=\"k\") for n in range(1, order + 1)]\n",
    "[\n",
    "    plt.text(n * map.Ny - 1 + map.Ny / 2, len(t) / 2, n, color=\"k\")\n",
    "    for n in range(order + 1)\n",
    "]\n",
    "plt.gca().axis(\"off\")\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll tackle the linear problem."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    Since this is still an experimental feature, the user interface is a little clunky.\n",
    "    Solving the linear problem for temporal maps will become easier in the next release of the code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the ``solve`` method in the [linalg](linalg.html#starry.linalg) module to solve a custom linear system. We'll set the prior mean of the coefficients to zero, except for the first one, which we set to unity (since this is the prior on the map amplitude). We'll give all the coefficients a prior variance of $10^{-2}$, except for the first one, whose variance we'll set to unity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.zeros(A.shape[1])\n",
    "mu[0] = 1.0\n",
    "L = np.ones(map.Ny * (order + 1)) * 1e-2\n",
    "L[0] = 1.0\n",
    "x, cho_cov = starry.linalg.solve(A, flux, C=flux_err ** 2, mu=mu, L=L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``solve`` method returns the amplitude-weighted coefficients ``x`` and the Cholesky factorization of the posterior covariance. Let's plot the best fit model against the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = A.dot(x)\n",
    "plt.plot(time, flux, \".\", ms=3, label=\"data\")\n",
    "plt.plot(time, model, label=\"model\")\n",
    "plt.ylabel(\"flux [normalized]\")\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks really good! The residuals are fairly white:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, flux - model, \".\", ms=3, label=\"data\")\n",
    "plt.axhline(flux_err, color=\"C0\", alpha=0.2)\n",
    "plt.axhline(-flux_err, color=\"C0\", alpha=0.2)\n",
    "plt.ylabel(\"residuals\")\n",
    "plt.xlabel(\"time [days]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now visualize the solution. Recall that the coefficients of the map at time $t$ are given by\n",
    "\n",
    "$$\n",
    "\\mathbf{x}(t) = \\mathbf{x}\\,\\Big|_{t=0} \\,\\,\\,+\\,\\,\\, \\mathbf{\\dot{x}}\\,\\Big|_{t=0}t \\,\\,\\,+\\,\\,\\, \\frac{1}{2}\\mathbf{\\ddot{x}}\\,\\Big|_{t=0}t^2 \\,\\,\\,+\\,\\,\\, ...\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate the image\n",
    "image = np.empty((len(time_ani), res, res))\n",
    "\n",
    "# Compute the weights of each coefficient in the Taylor expansion\n",
    "t_ani = 2.0 * (time_ani / time_ani[-1] - 0.5)\n",
    "T_ani = np.vander(t_ani, order + 1, increasing=True) * coeff\n",
    "\n",
    "# At each point in time, compute the map coefficients\n",
    "# and render the image\n",
    "for n in range(len(time_ani)):\n",
    "    xn = x.reshape(order + 1, -1).T.dot(T_ani[n])\n",
    "    map.amp = xn[0]\n",
    "    map[1:, :] = xn[1:] / map.amp\n",
    "    image[n] = map.render(res=res, projection=\"rect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "replace_input_with": "map.show(image=image, projection=\"rect\")\nmap.show(image=true_image_rect, projection=\"rect\")"
   },
   "outputs": [],
   "source": [
    "# HACK: Manually render both maps so that they are in sync\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "fig, ax = plt.subplots(2, figsize=(7, 6))\n",
    "\n",
    "img1 = ax[0].imshow(\n",
    "    image[0], origin=\"lower\", cmap=\"plasma\", extent=(-180, 180, -90, 90)\n",
    ")\n",
    "img2 = ax[1].imshow(\n",
    "    true_image_rect[0], origin=\"lower\", cmap=\"plasma\", extent=(-180, 180, -90, 90)\n",
    ")\n",
    "\n",
    "for i, axis in enumerate(ax):\n",
    "    lats = np.linspace(-90, 90, 7)[1:-1]\n",
    "    lons = np.linspace(-180, 180, 13)\n",
    "    latlines = [None for n in lats]\n",
    "    for n, lat in enumerate(lats):\n",
    "        latlines[n] = axis.axhline(lat, color=\"k\", lw=0.5, alpha=0.5, zorder=100)\n",
    "    lonlines = [None for n in lons]\n",
    "    for n, lon in enumerate(lons):\n",
    "        lonlines[n] = axis.axvline(lon, color=\"k\", lw=0.5, alpha=0.5, zorder=100)\n",
    "    axis.set_yticks(lats)\n",
    "    axis.set_ylabel(\"Latitude [deg]\")\n",
    "    axis.set_xticks(lons)\n",
    "    if i == 1:\n",
    "        axis.set_xlabel(\"Longitude [deg]\")\n",
    "    else:\n",
    "        axis.set_xticklabels([])\n",
    "\n",
    "\n",
    "def updatefig(i):\n",
    "    img1.set_array(image[i])\n",
    "    img2.set_array(true_image_rect[i])\n",
    "    return (img1, img2)\n",
    "\n",
    "\n",
    "ani = FuncAnimation(fig, updatefig, interval=75, blit=True, frames=image.shape[0],)\n",
    "\n",
    "plt.close()\n",
    "display(HTML(ani.to_html5_video()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior mean map is shown at the top and the original map is shown at the bottom. We're able to recover the three spots and the general westward motion due to differential rotation, even though we never explicitly assumed anything about the number / shape / size of the spots or the strength of the differential rotation. There are, however, lots of artifacts in the solution, and one of the spots seems to disappear toward the end. They are also elongated latitudinally.\n",
    "\n",
    "Note, however, that this is a fundamental limitation of the mapping problem, since the [null space](NullSpace.ipynb) is huge! Unless we have **good prior information**, in many cases our maps will **look nothing like the true image of the star.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling differential rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's explicitly assume the variability we see is due to differential rotation. This is an experimental feature in `starry`, which you can read more about [here](DifferentialRotation.ipynb). The idea is to Taylor expand the differential rotation operator and truncate the differentially-rotated map to the current map resolution. This is **slow** and **becomes unstable as time goes on** (since polynomials diverge toward infinity!) Below, we're using a 2nd order expansion, which will help in modeling all 30 days of data at once. But it comes at the cost of extra computational overhead, so we're going to again limit the map to a degree 5 spherical harmonic expansion."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    We're still working on the differential rotation operator, so it will likely become a lot more \n",
    "    efficient in the near future!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = starry.Map(5, 1, drorder=2)\n",
    "map.inc = inc\n",
    "map.alpha = alpha\n",
    "map[1] = u1\n",
    "\n",
    "# Set the prior as before.\n",
    "# We place a stronger prior on the coefficients\n",
    "# to prevent the solution from blowing up (since\n",
    "# the differential rotation operator isn't very\n",
    "# numerically stable).\n",
    "mu = np.zeros(map.Ny)\n",
    "mu[0] = 1.0\n",
    "L = np.ones(map.Ny) * 1e-4\n",
    "L[0] = 1.0\n",
    "map.set_prior(mu=mu, L=L)\n",
    "map.set_data(flux, C=flux_err ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Center the array of rotational phases for numerical stability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmid = 0.5 * (time[-1] - time[0])\n",
    "theta = 360.0 / P * (time - tmid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve the linear problem (note that this automatically sets the map's coefficients to the maximum a posteriori solution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "soln = map.solve(theta=theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and plot the model and the residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "model = map.flux(theta=theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, flux, \".\", ms=3, label=\"data\")\n",
    "plt.plot(time, model, label=\"model\")\n",
    "plt.ylabel(\"flux [normalized]\")\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, flux - model, \".\", ms=3, label=\"data\")\n",
    "plt.axhline(flux_err, color=\"C0\", alpha=0.2)\n",
    "plt.axhline(-flux_err, color=\"C0\", alpha=0.2)\n",
    "plt.ylabel(\"residuals\")\n",
    "plt.xlabel(\"time [days]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit is decent, but note how the scatter is much larger than the standard deviation of the data (blue lines).We're also struggling to model the light curve at the edges of the timeseries. The oscillatory pattern in the residuals is due to the fact that our model assumes perfect differential rotation; i.e., that all features get sheared over time depending on their latitude. Our synthetic dataset consists of circular spots that move relative to each other, but don't *themselves* undergo any shearing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the actual surface looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "replace_input_with": "map.show(theta=theta, projection=\"rect\")\nmap.show(image=true_image_rect, projection=\"rect\")"
   },
   "outputs": [],
   "source": [
    "# HACK: Manually render both maps so that they are in sync\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "fig, ax = plt.subplots(2, figsize=(7, 6))\n",
    "\n",
    "tmid = 0.5 * (time_ani[-1] - time_ani[0])\n",
    "theta = 360.0 / P * (time_ani - tmid)\n",
    "image = map.render(theta=theta, res=res, projection=\"rect\")\n",
    "\n",
    "img1 = ax[0].imshow(\n",
    "    image[0], origin=\"lower\", cmap=\"plasma\", extent=(-180, 180, -90, 90)\n",
    ")\n",
    "img2 = ax[1].imshow(\n",
    "    true_image_rect[0], origin=\"lower\", cmap=\"plasma\", extent=(-180, 180, -90, 90)\n",
    ")\n",
    "\n",
    "for i, axis in enumerate(ax):\n",
    "    lats = np.linspace(-90, 90, 7)[1:-1]\n",
    "    lons = np.linspace(-180, 180, 13)\n",
    "    latlines = [None for n in lats]\n",
    "    for n, lat in enumerate(lats):\n",
    "        latlines[n] = axis.axhline(lat, color=\"k\", lw=0.5, alpha=0.5, zorder=100)\n",
    "    lonlines = [None for n in lons]\n",
    "    for n, lon in enumerate(lons):\n",
    "        lonlines[n] = axis.axvline(lon, color=\"k\", lw=0.5, alpha=0.5, zorder=100)\n",
    "    axis.set_yticks(lats)\n",
    "    axis.set_ylabel(\"Latitude [deg]\")\n",
    "    axis.set_xticks(lons)\n",
    "    if i == 1:\n",
    "        axis.set_xlabel(\"Longitude [deg]\")\n",
    "    else:\n",
    "        axis.set_xticklabels([])\n",
    "\n",
    "\n",
    "def updatefig(i):\n",
    "    img1.set_array(image[i])\n",
    "    img2.set_array(true_image_rect[i])\n",
    "    return (img1, img2)\n",
    "\n",
    "\n",
    "ani = FuncAnimation(fig, updatefig, interval=75, blit=True, frames=image.shape[0],)\n",
    "\n",
    "plt.close()\n",
    "display(HTML(ani.to_html5_video()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One could argue that there are three features in the solution that kind of track the true spots, but they're shifted in latitude and elongated in longitude. They are also **very** prior-dependent (try experimenting with the value of $\\Lambda$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spots rotating at different rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we could place an even stronger prior on the problem and assume the stellar surface consists of a few discrete spots undergoing differential rotation.\n",
    "\n",
    "Since the ``starry`` model is linear, we can instantiate several maps rotating at different rates, compute their light curves, and add them all together. We scale the result by the free variable ``scale`` to get the normalization correct.\n",
    "\n",
    "We're going to define a ``pymc3`` model for the problem, but we're not going to do any sampling -- rather, we're going to use the ``optimize`` function from ``exoplanet`` to find the best spot properties (and that requires a ``pymc3`` model).\n",
    "\n",
    "As we will see, finding the correct spot parameters is **extremely difficult** even when our model is *exactly* the correct description of the problem. That's because the likelihood space is extremely degenerate and extremely multi-modal. Optimization yields completely different results depending on how exactly we initialize the solver and on how stringent our priors our. For simplicity, below we assume we know **everything** except for the latitude and longitude of each of the spots and the overall light curve normalization. We therefore fix the spot intensity, size, and differential rotation parameter at their **true** values. As we will see, even in this ideal case, we only get the correct solution if we initialize the solver very close to the true spot locations!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    This next bit requires ``lazy`` evaluation mode. Switching between evaluation modes within a Python\n",
    "    session is not currently supported. We do it below, but this is not advised in general, as it may\n",
    "    lead to unexpected behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch evaluation modes.\n",
    "# WARNING: Don't try this at home! Start a new Python session instead.\n",
    "starry.config._lazy = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function that instantiates a ``pymc3`` model and runs an optimizer to find the spot locations. The function returns the best model for the light curve and for the image of the surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import exoplanet as xo\n",
    "\n",
    "\n",
    "def solve(lat_guess, lon_guess):\n",
    "\n",
    "    nspots = len(lat_guess)\n",
    "\n",
    "    with pm.Model() as model:\n",
    "\n",
    "        # Keep track of these things\n",
    "        map = [None for n in range(nspots)]\n",
    "        frac = [None for n in range(nspots)]\n",
    "        flux_model = [None for n in range(nspots)]\n",
    "        omega = [None for n in range(nspots)]\n",
    "\n",
    "        # Flux normalization\n",
    "        scale = pm.Uniform(\"scale\", lower=0, upper=1.0, testval=1.0 / nspots)\n",
    "\n",
    "        # Add each spot\n",
    "        for n in range(nspots):\n",
    "\n",
    "            # Spot parameters\n",
    "            lat = pm.Uniform(\n",
    "                \"lat{}\".format(n), lower=-90, upper=90, testval=lat_guess[n]\n",
    "            )\n",
    "            lon = pm.Uniform(\n",
    "                \"lon{}\".format(n), lower=-180, upper=180, testval=lon_guess[n]\n",
    "            )\n",
    "\n",
    "            # Instantiate the map and add the spot\n",
    "            map[n] = starry.Map(10, 1)\n",
    "            map[n].inc = inc\n",
    "            map[n][1] = u1\n",
    "            map[n].add_spot(\n",
    "                intensity=intensity, sigma=sigma, lat=lat, lon=lon,\n",
    "            )\n",
    "            omega[n] = omega_eq * (1 - alpha * np.sin(lat * np.pi / 180.0) ** 2)\n",
    "            flux_model[n] = map[n].flux(theta=omega[n] * time)\n",
    "\n",
    "        # Compute the model\n",
    "        flux_model = scale * pm.math.sum(flux_model, axis=0)\n",
    "        pm.Deterministic(\"flux_model\", flux_model)\n",
    "\n",
    "        # Save our initial guess\n",
    "        flux_model_guess = xo.eval_in_model(flux_model)\n",
    "\n",
    "        # The likelihood function\n",
    "        pm.Normal(\"obs\", mu=flux_model, sd=flux_err, observed=flux)\n",
    "\n",
    "        # Optimize!\n",
    "        map_soln = xo.optimize()\n",
    "\n",
    "        # Render the map\n",
    "        image = np.zeros((len(time_ani), res, res))\n",
    "        for n in range(nspots):\n",
    "            tmp = xo.eval_in_model(\n",
    "                map[n].render(projection=\"rect\", res=res), point=map_soln,\n",
    "            )\n",
    "            shift = np.array(\n",
    "                (xo.eval_in_model(omega[n], point=map_soln) - omega_eq)\n",
    "                * time_ani\n",
    "                * res\n",
    "                / 360,\n",
    "                dtype=int,\n",
    "            )\n",
    "            for n in range(len(time_ani)):\n",
    "                image[n] += np.roll(tmp, shift[n], axis=1)\n",
    "\n",
    "    # Return the model for the flux and the map\n",
    "    return map_soln[\"flux_model\"], image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our first experiment, we initialize the spot locations at random values centered on the true locations and with a standard deviation of **5 degrees**. These are therefore **very** good guesses. Let's see how we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "lat_guess = true_lats + 5 * np.random.randn(3)\n",
    "lon_guess = true_lons + 5 * np.random.randn(3)\n",
    "model1, image1 = solve(lat_guess, lon_guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a huge improvement in the log likelihood! Here's the final model and residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, flux, \".\", ms=3, label=\"data\")\n",
    "plt.plot(time, model1, label=\"good initial guesss\")\n",
    "plt.ylabel(\"flux [normalized]\")\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, flux - model1, \".\", ms=3, label=\"data\")\n",
    "plt.axhline(flux_err, color=\"C0\", alpha=0.2)\n",
    "plt.axhline(-flux_err, color=\"C0\", alpha=0.2)\n",
    "plt.ylabel(\"residuals\")\n",
    "plt.xlabel(\"time [days]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have undoubtedly found the correct solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "replace_input_with": "map.show(image=image1, projection=\"rect\")\nmap.show(image=true_image_rect, projection=\"rect\")"
   },
   "outputs": [],
   "source": [
    "# HACK: Manually render both maps so that they are in sync\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "fig, ax = plt.subplots(2, figsize=(7, 6))\n",
    "\n",
    "img1 = ax[0].imshow(\n",
    "    image1[0], origin=\"lower\", cmap=\"plasma\", extent=(-180, 180, -90, 90)\n",
    ")\n",
    "img2 = ax[1].imshow(\n",
    "    true_image_rect[0], origin=\"lower\", cmap=\"plasma\", extent=(-180, 180, -90, 90)\n",
    ")\n",
    "\n",
    "for i, axis in enumerate(ax):\n",
    "    lats = np.linspace(-90, 90, 7)[1:-1]\n",
    "    lons = np.linspace(-180, 180, 13)\n",
    "    latlines = [None for n in lats]\n",
    "    for n, lat in enumerate(lats):\n",
    "        latlines[n] = axis.axhline(lat, color=\"k\", lw=0.5, alpha=0.5, zorder=100)\n",
    "    lonlines = [None for n in lons]\n",
    "    for n, lon in enumerate(lons):\n",
    "        lonlines[n] = axis.axvline(lon, color=\"k\", lw=0.5, alpha=0.5, zorder=100)\n",
    "    axis.set_yticks(lats)\n",
    "    axis.set_ylabel(\"Latitude [deg]\")\n",
    "    axis.set_xticks(lons)\n",
    "    if i == 1:\n",
    "        axis.set_xlabel(\"Longitude [deg]\")\n",
    "    else:\n",
    "        axis.set_xticklabels([])\n",
    "\n",
    "\n",
    "def updatefig(i):\n",
    "    img1.set_array(image1[i])\n",
    "    img2.set_array(true_image_rect[i])\n",
    "    return (img1, img2)\n",
    "\n",
    "\n",
    "ani = FuncAnimation(fig, updatefig, interval=75, blit=True, frames=image.shape[0],)\n",
    "\n",
    "plt.close()\n",
    "display(HTML(ani.to_html5_video()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to drive home the point of how difficult it is to model light curves with discrete spots, let's instead initialize the solver with a slightly higher standard deviation in our guesses: **15 degrees**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "lat_guess = true_lats + 15 * np.random.randn(3)\n",
    "lon_guess = true_lons + 15 * np.random.randn(3)\n",
    "model2, image2 = solve(lat_guess, lon_guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how our log likelihood is much, much smaller than before. Here's the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, flux, \".\", ms=3, label=\"data\")\n",
    "plt.plot(time, model2, label=\"bad initial guesss\")\n",
    "plt.ylabel(\"flux [normalized]\")\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, flux - model2, \".\", ms=3, label=\"data\")\n",
    "plt.axhline(flux_err, color=\"C0\", alpha=0.2)\n",
    "plt.axhline(-flux_err, color=\"C0\", alpha=0.2)\n",
    "plt.ylabel(\"residuals\")\n",
    "plt.xlabel(\"time [days]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residuals are orders of magnitude larger than the flux uncertainty. Check out the \"best\" map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "replace_input_with": "map.show(image=image2, projection=\"rect\")\nmap.show(image=true_image_rect, projection=\"rect\")"
   },
   "outputs": [],
   "source": [
    "# HACK: Manually render both maps so that they are in sync\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "fig, ax = plt.subplots(2, figsize=(7, 6))\n",
    "\n",
    "img1 = ax[0].imshow(\n",
    "    image2[0], origin=\"lower\", cmap=\"plasma\", extent=(-180, 180, -90, 90)\n",
    ")\n",
    "img2 = ax[1].imshow(\n",
    "    true_image_rect[0], origin=\"lower\", cmap=\"plasma\", extent=(-180, 180, -90, 90)\n",
    ")\n",
    "\n",
    "for i, axis in enumerate(ax):\n",
    "    lats = np.linspace(-90, 90, 7)[1:-1]\n",
    "    lons = np.linspace(-180, 180, 13)\n",
    "    latlines = [None for n in lats]\n",
    "    for n, lat in enumerate(lats):\n",
    "        latlines[n] = axis.axhline(lat, color=\"k\", lw=0.5, alpha=0.5, zorder=100)\n",
    "    lonlines = [None for n in lons]\n",
    "    for n, lon in enumerate(lons):\n",
    "        lonlines[n] = axis.axvline(lon, color=\"k\", lw=0.5, alpha=0.5, zorder=100)\n",
    "    axis.set_yticks(lats)\n",
    "    axis.set_ylabel(\"Latitude [deg]\")\n",
    "    axis.set_xticks(lons)\n",
    "    if i == 1:\n",
    "        axis.set_xlabel(\"Longitude [deg]\")\n",
    "    else:\n",
    "        axis.set_xticklabels([])\n",
    "\n",
    "\n",
    "def updatefig(i):\n",
    "    img1.set_array(image2[i])\n",
    "    img2.set_array(true_image_rect[i])\n",
    "    return (img1, img2)\n",
    "\n",
    "\n",
    "ani = FuncAnimation(fig, updatefig, interval=75, blit=True, frames=image.shape[0],)\n",
    "\n",
    "plt.close()\n",
    "display(HTML(ani.to_html5_video()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly converged to a (very bad) local minimum that doesn't even come close to describing the true surface of the star.\n",
    "\n",
    "The bottom line here is that unless we have a very good initial guess (and/or a very good prior), it is **really** hard to do optimization in this space. However, if you're patient, you could try initializing the solver at many different locations. You could also try optimizing for only a few variables at a time (for instance, solve for the position of the first spot with the other two fixed, then the position of the second spot with the other two fixed, and so forth), which sometimes helps with convergence. But that's all beyond the scope of this simple tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discussed three different methods to model time variability. Arguably none of them did particularly well. The [discrete spot model](#3.-Spots-rotating-at-different-rates) got the correct solution when we fixed most of the parameters at their true values and started with a *really* good initial guess, but that's hardly ever going to help us with real data. The [differential rotation model](#2.-Modeling-differential-rotation) was pretty *meh* and isn't scalable to high degrees or long light curves because of how unstable the expansion of the differential rotation operator is. I'm a fan of the [Taylor model](#1.-Using-a-Taylor-expansion), but it is quite ill-conditioned and therefore needs very strong priors to avoid overfitting. For real data, you should experiment with all three models, as some may perform better depending on the problem.\n",
    "\n",
    "Kepp in mind that in all cases, the only way to get a **good solution** is to have a **good prior** (or a good initial guess). That's because of the ever-present issue of the [null space](NullSpace.ipynb). The mapping problem is difficult enough when the maps are static, and becomes nearly intractable when there's time variability.\n",
    "\n",
    "However, there *are* many ways to maximize the information one can obtain about a stellar surface when there's time variability, and they all rely on techniques to break degeneracies. Please refer to the [null space](NullSpace.ipynb) tutorial for more information."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
