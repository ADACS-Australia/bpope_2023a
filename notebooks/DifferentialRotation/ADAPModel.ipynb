{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebook_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import starry\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib import colors\n",
    "import time\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import correlate\n",
    "from scipy.optimize import curve_fit\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import theano.sparse as ts\n",
    "import pymc3 as pm\n",
    "import pymc3.distributions.transforms as tr\n",
    "import exoplanet as exo\n",
    "from scipy.sparse import csr_matrix, csc_matrix\n",
    "from emcee.autocorr import integrated_time\n",
    "import logging\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starry.config.lazy = False\n",
    "starry.config.quiet = True\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some dummy classes to store the true parameters and the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Truth(object):\n",
    "    pass\n",
    "\n",
    "\n",
    "truth = Truth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    pass\n",
    "\n",
    "\n",
    "data = Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define the true parameters of the data. We're going to model ``30`` discrete Gaussian spots centered at various latitudes, each rotating at a period given by the linear differential rotation law. Our dataset will mimic one quarter of Kepler data: about ``4500`` points roughly evenly spaced over ``90`` days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth.ydeg = 20  # degree of the Ylm expansion\n",
    "truth.inc = 60.0  # stellar inclination\n",
    "truth.prot = 1.129337  # stellar rotation period\n",
    "truth.alpha = 0.1  # differential shear\n",
    "\n",
    "truth.nspots = 30  # number of spots\n",
    "truth.tau_mu = 20 * truth.prot  # average spot timescale\n",
    "truth.tau_sig = 1.0  # spot timescale std. dev.\n",
    "\n",
    "data.tmax = 90  # length of timeseries in days\n",
    "data.tpad = 50.0  # spots can emerge this many days before t = 0\n",
    "data.npts = 4499  # number of cadences\n",
    "data.t = np.sort(\n",
    "    np.linspace(0, data.tmax, data.npts)\n",
    "    + (1e-3 * data.tmax / data.npts) * np.random.randn(data.npts)\n",
    ")  # time array\n",
    "data.ferr = 1e-3  # photometric noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given those parameters, let's draw from some fiducial distributions to obtain our spots, their emergence times, and their timescales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a starry map\n",
    "map = starry.Map(truth.ydeg)\n",
    "\n",
    "# Spot latitude distribution: isotropic\n",
    "lat = lambda: (np.arccos(2 * np.random.random() - 1) - 0.5 * np.pi) * 180 / np.pi\n",
    "\n",
    "# Spot longitude distribution: isotropic\n",
    "lon = lambda: 360.0 * np.random.random()\n",
    "\n",
    "# Spot size distribution\n",
    "sigma = lambda: max(0.01, np.exp(-3.5 + 0.4 * np.random.randn()))\n",
    "\n",
    "# Spot intensity distribution\n",
    "intensity = lambda: -min(1.0, 10 * np.exp(-3 + 0.5 * np.random.randn()))\n",
    "\n",
    "# Generate the Ylm coeffs for each spot\n",
    "truth.y = np.empty((truth.nspots, (truth.ydeg + 1) ** 2))\n",
    "truth.lat = np.zeros(truth.nspots)\n",
    "truth.lon = np.zeros(truth.nspots)\n",
    "truth.sigma = np.zeros(truth.nspots)\n",
    "truth.intensity = np.zeros(truth.nspots)\n",
    "for n in tqdm(range(truth.nspots)):\n",
    "    map.reset()\n",
    "    truth.lat[n] = lat()\n",
    "    truth.lon[n] = lon()\n",
    "    truth.sigma[n] = sigma()\n",
    "    truth.intensity[n] = intensity()\n",
    "    map.add_spot(\n",
    "        lat=truth.lat[n],\n",
    "        lon=truth.lon[n],\n",
    "        sigma=truth.sigma[n],\n",
    "        intensity=truth.intensity[n],\n",
    "    )\n",
    "    truth.y[n] = map.amp * map.y\n",
    "truth.y[:, 0] = 0\n",
    "\n",
    "# Spot timescales\n",
    "truth.tau = truth.tau_mu + truth.tau_sig * np.random.randn(truth.nspots)\n",
    "\n",
    "# Spot emergence times\n",
    "truth.t0 = np.sort((data.tmax + data.tpad) * np.random.random(truth.nspots) - data.tpad)\n",
    "\n",
    "# Spot amplitudes as a function of time\n",
    "truth.a = np.exp(\n",
    "    -((data.t.reshape(1, -1) - truth.t0.reshape(-1, 1)) ** 2)\n",
    "    / (2 * truth.tau.reshape(-1, 1) ** 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(12, 10), sharey=True)\n",
    "ax = ax.flatten()\n",
    "ax[0].hist(truth.tau)\n",
    "ax[0].set_xlabel(\"timescale [days]\")\n",
    "\n",
    "ax[1].hist(truth.t0)\n",
    "ax[1].set_xlabel(\"emergence time [days]\")\n",
    "\n",
    "ax[2].hist(truth.lat)\n",
    "ax[2].set_xlabel(\"latitude [degrees]\")\n",
    "\n",
    "ax[3].hist(truth.lon)\n",
    "ax[3].set_xlabel(\"longitude [degrees]\")\n",
    "\n",
    "ax[4].hist(truth.intensity)\n",
    "ax[4].set_xlabel(\"intensity [fractional]\")\n",
    "\n",
    "ax[5].hist(truth.sigma)\n",
    "ax[5].set_xlabel(\"size [fractional]\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    truth.a, aspect=\"auto\", extent=(0, data.tmax, truth.nspots, 0), vmin=0, vmax=1\n",
    ")\n",
    "plt.colorbar(label=\"amplitude\")\n",
    "plt.plot(truth.t0, 0.5 + np.arange(truth.nspots), \"w|\", ms=7.5)\n",
    "plt.xlim(0, data.tmax)\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.ylabel(\"spot number\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are our actual spots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 6\n",
    "ny = 5\n",
    "if nx is None or ny is None:\n",
    "    nx = 1 + int(np.ceil(np.sqrt(truth.nspots)))\n",
    "    ny = 1\n",
    "    while ny * nx < truth.nspots:\n",
    "        ny += 1\n",
    "fig, ax = plt.subplots(ny, nx, figsize=(12, 5))\n",
    "ax = ax.flatten()\n",
    "for axis in ax:\n",
    "    axis.axis(\"off\")\n",
    "for k in tqdm(range(truth.nspots)):\n",
    "    map.reset()\n",
    "    map[1:, :] = truth.y[k, 1:]\n",
    "    img = np.pi * map.render(projection=\"moll\", res=100)\n",
    "    ax[k].imshow(\n",
    "        img,\n",
    "        origin=\"lower\",\n",
    "        extent=(-1, 1, -0.5, 0.5),\n",
    "        cmap=\"Greys_r\",\n",
    "        vmin=0.0,\n",
    "        vmax=1,\n",
    "    )\n",
    "    x_el = np.linspace(-1, 1, 1000)\n",
    "    y_el = 0.5 * np.sqrt(1 - x_el ** 2)\n",
    "    ax[k].plot(x_el, y_el, \"k-\", lw=1, clip_on=False)\n",
    "    ax[k].plot(x_el, -y_el, \"k-\", lw=1, clip_on=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the empirical mean and covariance of the spot distribution. We're going to use this as our **prior** below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 99999\n",
    "y = np.empty((N, (truth.ydeg + 1) ** 2 - 1))\n",
    "for n in tqdm(range(N)):\n",
    "    map.reset()\n",
    "    map.add_spot(lat=lat(), lon=lon(), sigma=sigma(), intensity=intensity())\n",
    "    y[n] = map.amp * map.y[1:]\n",
    "\n",
    "truth.ymu = np.mean(y, axis=0)\n",
    "truth.ycov = np.cov(y.T)\n",
    "truth.ycov[np.diag_indices_from(truth.ycov)] += 1e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw and visualize a sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map.reset()\n",
    "map[1:, :] = np.random.multivariate_normal(truth.ymu, truth.ycov)\n",
    "map.show(projection=\"moll\", colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now visualize the star as a movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie(\n",
    "    t=data.t,\n",
    "    y=truth.y,\n",
    "    lats=truth.lat,\n",
    "    prot=truth.prot,\n",
    "    alpha=truth.alpha,\n",
    "    a=truth.a,\n",
    "    downsamp=10,\n",
    "    res=300,\n",
    "    projection=\"moll\",\n",
    "):\n",
    "\n",
    "    # Instantiate a map of the right degree\n",
    "    map = starry.Map(ydeg=np.sqrt(y.shape[1]) - 1)\n",
    "\n",
    "    # Theano function for rendering one spot\n",
    "    def _render(y, theta, res):\n",
    "        \"\"\"Render the map on a Mollweide grid.\"\"\"\n",
    "        # Compute the Cartesian grid\n",
    "        if projection == \"moll\":\n",
    "            xyz = map.ops.compute_moll_grid(res)[-1]\n",
    "        else:\n",
    "            xyz = map.ops.compute_rect_grid(res)[-1]\n",
    "\n",
    "        # Compute the polynomial basis\n",
    "        pT = map.ops.pT(xyz[0], xyz[1], xyz[2])\n",
    "\n",
    "        # Rotate the map\n",
    "        Ry = map.ops.left_project(\n",
    "            tt.transpose(tt.tile(y, [theta.shape[0], 1])),\n",
    "            np.array(0.5 * np.pi),\n",
    "            np.array(0.0),\n",
    "            theta,\n",
    "            np.array(0.0),\n",
    "            np.array(np.inf),\n",
    "            np.array(0.0),\n",
    "        )\n",
    "\n",
    "        # Change basis to polynomials\n",
    "        A1Ry = ts.dot(map.ops.A1, Ry)\n",
    "\n",
    "        # Dot the polynomial into the basis\n",
    "        res = tt.reshape(tt.dot(pT, A1Ry), [res, res, -1])\n",
    "\n",
    "        # We need the shape to be (nframes, npix, npix)\n",
    "        return res.dimshuffle(2, 0, 1)\n",
    "\n",
    "    # Compile the theano function\n",
    "    with theano.configparser.change_flags(compute_test_value=\"off\"):\n",
    "        _y = tt.dvector()\n",
    "        _theta = tt.dvector()\n",
    "        _res = tt.iscalar()\n",
    "        render_spot = theano.function([_y, _theta, _res], _render(_y, _theta, _res))\n",
    "\n",
    "    # Sum the contribution from each spot in the co-rotating frame\n",
    "    nim = len(t[::downsamp])\n",
    "    img = np.ones((nim, res, res))\n",
    "    theta_eq = 2 * np.pi / prot * t\n",
    "    theta = theta_eq.reshape(1, -1) * (\n",
    "        1 - alpha * np.sin(np.pi / 180 * lats.reshape(-1, 1)) ** 2\n",
    "    )\n",
    "    theta_diff = theta - theta_eq.reshape(1, -1)\n",
    "    for k in tqdm(range(len(lats))):\n",
    "        imgk = np.pi * render_spot(y[k], theta_diff[k, ::downsamp], res)\n",
    "        img += a[k, ::downsamp].reshape(-1, 1, 1) * imgk\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth.movie = get_movie()\n",
    "map.show(image=truth.movie, projection=\"moll\", colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the light curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(\n",
    "    t=data.t,\n",
    "    y=truth.y,\n",
    "    lats=truth.lat,\n",
    "    prot=truth.prot,\n",
    "    inc=truth.inc,\n",
    "    alpha=truth.alpha,\n",
    "    a=truth.a,\n",
    "):\n",
    "\n",
    "    # Instantiate a map of the right degree\n",
    "    map = starry.Map(ydeg=np.sqrt(y.shape[1]) - 1, inc=inc)\n",
    "\n",
    "    # Angular phases of each spot\n",
    "    theta_eq = 360.0 / prot * t\n",
    "    theta = theta_eq.reshape(1, -1) * (\n",
    "        1 - alpha * np.sin(np.pi / 180 * lats.reshape(-1, 1)) ** 2\n",
    "    )\n",
    "\n",
    "    # Sum the contribution from each spot\n",
    "    model = np.ones_like(t)\n",
    "    for k in range(len(lats)):\n",
    "        model += a[k] * map.design_matrix(theta=theta[k]).dot(y[k])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lc(t, fluxes, styles=None, nrow=5, ncol=3, figsize=(12, 10)):\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax_main = plt.subplot2grid((nrow, ncol), (0, 0), colspan=ncol, rowspan=2)\n",
    "    ax_sub = [\n",
    "        plt.subplot2grid((nrow, ncol), (2 + i, j))\n",
    "        for i in range(nrow - 2)\n",
    "        for j in range(ncol)\n",
    "    ]\n",
    "    nsub = len(ax_sub)\n",
    "    npts = len(t)\n",
    "\n",
    "    if styles is None:\n",
    "        styles = [dict() for flux in fluxes]\n",
    "    for flux, style in zip(fluxes, styles):\n",
    "        ax_main.plot(t, flux, **style)\n",
    "\n",
    "        for k, ax in enumerate(ax_sub):\n",
    "\n",
    "            a = int(k * npts / nsub)\n",
    "            b = int((k + 1) * npts / nsub)\n",
    "            ax.plot(t[a:b], flux[a:b], **style)\n",
    "\n",
    "    ax_main.legend(fontsize=12, loc=\"upper right\")\n",
    "\n",
    "    for label in ax_main.get_yticklabels() + ax_main.get_xticklabels():\n",
    "        label.set_fontsize(10)\n",
    "    for ax in ax_sub:\n",
    "        for label in ax.get_yticklabels() + ax.get_xticklabels():\n",
    "            label.set_fontsize(8)\n",
    "    ax_main.set_ylabel(\"flux\")\n",
    "    for ax in ax_sub[-ncol:]:\n",
    "        ax.set_xlabel(\"time [days]\", fontsize=12)\n",
    "    for ax in ax_sub[::ncol]:\n",
    "        ax.set_ylabel(\"flux\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth.flux0 = get_model(alpha=0)\n",
    "truth.flux = get_model(alpha=truth.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orange is without differential rotation; blue is with differential rotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lc(\n",
    "    data.t,\n",
    "    [truth.flux0, truth.flux],\n",
    "    styles=[\n",
    "        dict(color=\"C1\", lw=1, alpha=0.5, label=\"solid\"),\n",
    "        dict(color=\"C0\", lw=2, label=\"diff rot\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, generate the dataset we'll do inference on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.flux = truth.flux + data.ferr * np.random.randn(len(truth.flux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lc(\n",
    "    data.t,\n",
    "    [truth.flux, data.flux],\n",
    "    styles=[\n",
    "        dict(color=\"C0\", lw=1, alpha=0.5, label=\"true\"),\n",
    "        dict(color=\"k\", ls=\"None\", marker=\".\", ms=2, label=\"observed\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do inference. Here are the data and parameters we'll assume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydeg = 10  # Ylm degree of the inferred map (this is < the true map!)\n",
    "N = (ydeg + 1) ** 2  # number of coefficients per node\n",
    "nnodes = 100  # number of nodes in the linear interpolation\n",
    "\n",
    "# The dataset\n",
    "t = data.t\n",
    "flux = data.flux\n",
    "ferr = data.ferr\n",
    "npts = data.npts\n",
    "\n",
    "# Our priors, which we take to be the actual\n",
    "# mean and covariance of the process that generated\n",
    "# the light curve. In reality, we'd marginalize over\n",
    "# these\n",
    "ymu = truth.ymu[: N - 1]  # mean of the spatial process\n",
    "ycov = truth.ycov[: N - 1, : N - 1]  # covariance of the spatial process\n",
    "\n",
    "# Things we'll assume we know exactly\n",
    "# (in reality, we'd marginalize over these)\n",
    "inc = truth.inc\n",
    "prot = truth.prot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our temporal model will be a linear interpolation of ``60`` spherical harmonic vectors evaluated on equally spaced nodes. Everything is linear, so we can pre-compute the `starry` design matrix and the interpolation matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute the starry design matrix\n",
    "map = starry.Map(ydeg, inc=inc)\n",
    "theta_x = 360.0 / prot * t\n",
    "X = map.design_matrix(theta=theta_x)[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute the interpolation matrix (linear)\n",
    "tnodes = np.linspace(t[0], t[-1], nnodes)\n",
    "dt = tnodes[1] - tnodes[0]\n",
    "diags = np.zeros((nnodes, npts))\n",
    "for k in range(nnodes):\n",
    "    w = 1 - np.abs(tnodes[k] - t) / dt\n",
    "    w[w < 0] = 0\n",
    "    diags[k] = w\n",
    "I = np.hstack([np.diag(diag) for diag in diags])\n",
    "\n",
    "# Visualize\n",
    "plt.figure()\n",
    "for diag in diags:\n",
    "    plt.plot(diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model for the flux is fully linear and given by\n",
    "\n",
    "$$\n",
    "\\mathbf{m} = 1 + \\mathbf{A} \\cdot \\mathbf{y}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{A}$ is the full design matrix (see below) and $\\mathbf{y}$ is the vector obtained by concatenating all ``60`` spherical harmonic vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the full design matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full design matrix\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "XL = block_diag(*[X for n in range(nnodes)])\n",
    "A = I.dot(XL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array(A)\n",
    "f[f == 0] = np.nan\n",
    "plt.imshow(f, aspect=\"auto\")\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to solve the linear L2 problem, so we need a Gaussian prior on $\\mathbf{y}$. This will be the product of a spatial prior and a temporal prior. The spatial prior is the Gaussian defined by the mean and covariance of our spot process, computed above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ls = np.array(ycov)\n",
    "plt.imshow(Ls)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temporal prior is a Gaussian Process that correlates nearby nodes to enforce that the surface of the star varies smoothly in time. We're using a Squared Exponential kernel with a single hyperparameter, `gptau`. For real data, the proper thing is to marginalize over `gptau`, but for simplicitly we manually tune it until we get a good fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gptau = 1.0\n",
    "if gptau > 0:\n",
    "    k = np.arange(nnodes).reshape(1, -1) - np.arange(nnodes).reshape(-1, 1)\n",
    "    Lt = np.exp(-0.5 * (k * dt / gptau) ** 2)\n",
    "else:\n",
    "    Lt = np.eye(nnodes)\n",
    "plt.imshow(Lt)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full covariance matrix is the Kronecker product of these two small matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.kron(Lt, Ls)\n",
    "L += 1e-12 * np.eye(L.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "f = np.array(L)\n",
    "vmax = np.max(np.abs(f))\n",
    "f /= vmax\n",
    "f[np.abs(f) < 1e-5] = 0\n",
    "\n",
    "imm = plt.imshow(np.log10(-f), cmap=\"Blues\", vmin=-5, vmax=0)\n",
    "cbm = plt.colorbar(shrink=0.65)\n",
    "cbm.set_ticks([-5, -4, -3, -2, -1, 0])\n",
    "cbm.set_ticklabels([r\"$-10^{%d}$\" % n for n in cbm.get_ticks()])\n",
    "imp = plt.imshow(np.log10(f), cmap=\"Reds\", vmin=-5, vmax=0)\n",
    "cbp = plt.colorbar(shrink=0.65)\n",
    "cbp.set_ticks([-5, -4, -3, -2, -1, 0])\n",
    "cbp.set_ticklabels([r\"$10^{%d}$\" % n for n in cbm.get_ticks()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prior mean is just the tiled mean of the spatial process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.concatenate([ymu for n in range(nnodes)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to do inference! Since everything is linear, this is just a (very large) matrix inverse problem, which we can tackle with ``starry`` in a few tens of seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y, y_cov = starry.linalg.solve(A, flux - 1.0, C=ferr**2, mu=mu, L=L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model (and uncertainty) is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 1 + A.dot(y)\n",
    "model_sig = np.diag(A.dot(y_cov).dot(A.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that it's a good fit to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lc(\n",
    "    t,\n",
    "    [flux, model],\n",
    "    styles=[\n",
    "        dict(color=\"k\", ls=\"None\", marker=\".\", ms=2, label=\"observed\"),\n",
    "        dict(color=\"C0\", lw=1, alpha=0.5, label=\"MAP\"),\n",
    "    ],\n",
    "    nrow=6,\n",
    "    ncol=3,\n",
    "    figsize=(12, 12),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the maximum a posterioiri (MAP) solution as a movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(y, time):\n",
    "    Y = y.reshape(nnodes, N - 1)\n",
    "    if time < tnodes[0]:\n",
    "        return Y[0]\n",
    "    elif time >= tnodes[-1]:\n",
    "        return Y[-1]\n",
    "    k = np.argmin(time >= tnodes) - 1\n",
    "    return ((time - tnodes[k]) * Y[k + 1] + (tnodes[k + 1] - time) * Y[k]) / (\n",
    "        tnodes[k + 1] - tnodes[k]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_image(_y):\n",
    "    map = starry.Map(ydeg, lazy=True)\n",
    "    map[1:, :] = _y\n",
    "    return np.pi * map.render(projection=\"moll\", res=300)\n",
    "\n",
    "\n",
    "with theano.configparser.change_flags(compute_test_value=\"off\"):\n",
    "    _y = tt.dvector()\n",
    "    get_image = theano.function([_y], _get_image(_y))\n",
    "\n",
    "\n",
    "downsamp = 10\n",
    "nim = len(t[::downsamp])\n",
    "movie = np.zeros((nim, 300, 300))\n",
    "for k in tqdm(range(nim)):\n",
    "    movie[k] = get_image(get_y(y, t[::downsamp][k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map.show(image=movie, projection=\"moll\", colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring the Differential Rotation Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given any draw from the posterior, we can compute the \"movie\" of the surface and determine the differential rotation shear implied by the temporal evolution of features. For simplicity, and as an example, let's compute the shear based on the MAP solution. It's easier if we evaluate the \"movie\" on a rectangular lat-lon grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_image(_y):\n",
    "    map = starry.Map(ydeg, lazy=True)\n",
    "    map[1:, :] = _y\n",
    "    return np.pi * map.render(projection=\"rect\", res=300)\n",
    "\n",
    "\n",
    "with theano.configparser.change_flags(compute_test_value=\"off\"):\n",
    "    _y = tt.dvector()\n",
    "    get_image = theano.function([_y], _get_image(_y))\n",
    "\n",
    "\n",
    "downsamp = 2\n",
    "nim = len(t[::downsamp])\n",
    "img = np.zeros((nim, 300, 300))\n",
    "for k in tqdm(range(nim)):\n",
    "    img[k] = get_image(get_y(y, t[::downsamp][k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon = map.get_latlon_grid(300, projection=\"rect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's obtain an estimate of the shear by computing the cross-correlation of the brightness of the star at a given latitude with the same brightness profile a certain amount of time earlier (for definiteness, we'll assume a lag of ``30`` frames, which is long enough so that shearing has changed the profile but not too long such that the spots have since dissipated; note that the results aren't too sensitive to this choice).\n",
    "\n",
    "For every latitude and at every frame, we compute the delta-longitude at which the autocorrelation peaks; this is an estimate of how far the feature has rotated over those ``30`` frames. We then average this shift over all frames to obtain the empirical shearing profile, and compare it to the true profile below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = 30\n",
    "\n",
    "Z = np.zeros((nim, 300)) * np.nan\n",
    "for k in range(300):\n",
    "\n",
    "    if np.abs(lat[k][0]) > 80:\n",
    "        Z[:, k] = np.nan\n",
    "        continue\n",
    "\n",
    "    f = img[:, k, :]\n",
    "    idx = ~np.isnan(f[0])\n",
    "    for j in range(lag, nim):\n",
    "        f0 = f[j - lag][idx]\n",
    "        fj = f[j][idx]\n",
    "        if len(fj):\n",
    "            corr = correlate(np.tile(f0, 2), fj, mode=\"valid\")\n",
    "            cc = len(corr) - 1 - np.argmax(corr)\n",
    "            if cc > len(corr) // 2:\n",
    "                cc -= len(corr) - 1\n",
    "            Z[j, k] = cc * np.nanmean(np.diff(lon[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the shear as a function of latitude and time (top panell) and averaged over time (bottom panel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, figsize=(10, 7), sharex=True)\n",
    "\n",
    "im = ax[0].imshow(\n",
    "    Z, aspect=\"auto\", extent=(-90, 90, data.tmax, 0), vmin=-20, vmax=20, cmap=\"RdBu\",\n",
    ")\n",
    "plt.colorbar(im, ax=ax[0], label=\"lag [deg]\")\n",
    "\n",
    "delt = t[lag] - t[0]\n",
    "signal = -truth.alpha * 360.0 / truth.prot * delt * np.sin(lat[:, 0] * np.pi / 180) ** 2\n",
    "ax[1].plot(lat[:, 0], signal, label=\"truth\", color=\"k\")\n",
    "ax[1].set_xlabel(\"latitude [deg]\")\n",
    "ax[1].set_ylabel(\"lag [deg]\")\n",
    "ax[0].set_ylabel(\"time [days]\")\n",
    "\n",
    "mean = np.nanmean(Z, axis=0)\n",
    "mean -= np.nanmax(mean)\n",
    "mean_err = np.nanstd(Z, axis=0)\n",
    "mean_err[lat[:, 0] < -inc] = 1e50\n",
    "\n",
    "mean_err[150:] = mean_err[:150][::-1]\n",
    "\n",
    "med = np.nanmedian(Z, axis=0)\n",
    "med -= np.nanmax(med)\n",
    "\n",
    "ax[1].plot(lat[:, 0], mean, label=\"mean\", color=\"C0\")\n",
    "ax[1].fill_between(\n",
    "    lat[:, 0], mean - mean_err, mean + mean_err, color=\"C0\", alpha=0.3,\n",
    ")\n",
    "\n",
    "ax[1].plot(lat[:, 0], med, label=\"median\", color=\"C1\")\n",
    "\n",
    "ax[1].set_xlim(-80, 80)\n",
    "ax[1].set_ylim(-20, 2)\n",
    "cb_ = plt.colorbar(im, ax=ax[1])\n",
    "cb_.ax.set_visible(False)\n",
    "ax[1].legend(bbox_to_anchor=(1.04, 0.5), loc=\"center left\", borderaxespad=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's actually fit a differential rotation law to the blue curve to get an empirical estimate of the shear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x, alpha):\n",
    "    return -alpha * 360.0 / truth.prot * delt * np.sin(x * np.pi / 180) ** 2\n",
    "\n",
    "\n",
    "x = np.array(lat[:, 0])\n",
    "y = mean - np.nanmax(mean)\n",
    "\n",
    "x = x[~np.isnan(y)]\n",
    "yerr = mean_err[~np.isnan(y)]\n",
    "y = y[~np.isnan(y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inferred shear is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = func(x, 1).reshape(-1, 1)\n",
    "alpha = np.linalg.solve((X.T / yerr ** 2).dot(X), (X.T / yerr ** 2).dot(y))[0]\n",
    "alpha_err = np.sqrt(1 / (X.T / yerr ** 2).dot(X))[0, 0]\n",
    "\n",
    "print(\"{:.3f} +/- {:.3f}\".format(alpha, alpha_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "\n",
    "plt.plot(x, y, color=\"C0\", label=\"fit\")\n",
    "plt.fill_between(x, y - yerr, y + yerr, alpha=0.3, color=\"C0\")\n",
    "plt.ylim(-20, 2)\n",
    "plt.plot(x, func(x, truth.alpha), color=\"k\", label=\"truth\")\n",
    "plt.xlabel(\"latitude [deg]\")\n",
    "plt.ylabel(\"lag [deg]\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring the spot timescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    img[:, 150, :].T, aspect=\"auto\", extent=(0, data.tmax, 0, 360), origin=\"lower\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = get_movie(projection=\"rect\", downsamp=2)\n",
    "plt.imshow(\n",
    "    img0[:, 150, :].T, aspect=\"auto\", extent=(0, data.tmax, 0, 360), origin=\"lower\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(50)\n",
    "tau = np.zeros(300)\n",
    "tau0 = np.zeros(300)\n",
    "step = t[::downsamp][1] - t[::downsamp][0]\n",
    "for k in range(300):\n",
    "    tau[k] = step * integrated_time(img[:, 150, k], quiet=True)\n",
    "    tau0[k] = step * integrated_time(img0[:, 150, k], quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tau0, histtype=\"step\", label=\"truth\", lw=2, bins=5)\n",
    "plt.hist(tau, histtype=\"step\", label=\"MAP\", lw=2, bins=5)\n",
    "plt.legend()\n",
    "plt.xlabel(\"autocorrelation time [days]\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True autocorr time: {:.2f} +/- {:.2f} days\".format(np.mean(tau0), np.std(tau0)))\n",
    "print(\n",
    "    \"Inferred autocorr time: {:.2f} +/- {:.2f} days\".format(np.mean(tau), np.std(tau))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
