{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eclipsing binary: Full solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we're continuing our tutorial on how to do inference. In [this notebook](EclipsingBinary_Generate.ipynb) we showed how to use `pymc3` to get posteriors over map coefficients of an eclipsing binary light curve, and in [this notebook](EclipsingBinary_Linear.ipynb) we did the same thing using the analytic linear formalism of `starry`.\n",
    "\n",
    "Here, we're going to combine the two methods. We're going to sample the nonlinear parameters (the orbital parameters, limb darkening coefficients, etc.) using `pymc3` and analytically *marginalize* over the linear parameters (the spherical harmonic coefficients) using the `starry` linear formalism.\n",
    "\n",
    "**Note that since we're using `pymc3`, we need to enable `lazy` evaluation mode in `starry`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import exoplanet as xo\n",
    "import os\n",
    "import starry\n",
    "from corner import corner\n",
    "import theano.tensor as tt\n",
    "\n",
    "np.random.seed(12)\n",
    "starry.config.lazy = True\n",
    "starry.config.quiet = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Let's load the EB dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input",
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "# Run the Generate notebook if needed\n",
    "if not os.path.exists(\"eb.npz\"):\n",
    "    import nbformat\n",
    "    from nbconvert.preprocessors import ExecutePreprocessor\n",
    "\n",
    "    with open(\"EclipsingBinary_Generate.ipynb\") as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "    ep = ExecutePreprocessor(timeout=600, kernel_name=\"python3\")\n",
    "    ep.preprocess(nb);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"eb.npz\", allow_pickle=True)\n",
    "A = data[\"A\"].item()\n",
    "B = data[\"B\"].item()\n",
    "t = data[\"t\"]\n",
    "flux = data[\"flux\"]\n",
    "sigma = data[\"sigma\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the light curve we're going to do inference on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 5))\n",
    "ax.plot(t, flux, \"k.\", alpha=0.5, ms=4)\n",
    "ax.set_xlabel(\"time [days]\", fontsize=24)\n",
    "ax.set_ylabel(\"normalized flux\", fontsize=24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we instantiate the primary, secondary, and system objects within a `pm.Model()` context.\n",
    "Here are the priors we are going to assume for the parameters of the primary:\n",
    "\n",
    "| Parameter      | True Value | Assumed Value / Prior     | Units          |\n",
    "| ---            | ---        | ---                       | ---            |\n",
    "|$\\mathrm{amp}$  | $1.0$      | $1.0$                     | $-$            |\n",
    "|$r$             | $1.0$      | $\\mathcal{N}(0.95,0.1^2)$ | $R_\\odot$      |\n",
    "|$m$             | $1.0$      | $\\mathcal{N}(1.05,0.1^2)$ | $M_\\odot$      |\n",
    "|$P_\\mathrm{rot}$| $1.25$     | $\\mathcal{N}(1.25,0.01^2)$| $\\mathrm{days}$|\n",
    "|$i$             | $80.0$     | $\\mathcal{N}(80.0,5.0^2)$ | $\\mathrm{deg}$ |\n",
    "|$u_1$           | $0.40$     | $\\mathrm{Kipping}$        | $-$            |\n",
    "|$u_2$           | $0.25$     | $\\mathrm{Kipping}$        | $-$            |\n",
    "\n",
    "And here are the priors we are going to assume for the secondary:\n",
    "\n",
    "| Parameter      | True Value | Assumed Value / Prior      | Units          |\n",
    "| ---            | ---        | ---                        | ---            |\n",
    "|$\\mathrm{amp}$  | $0.1$      | $0.1$                      | $-$            |\n",
    "|$r$             | $0.7$      | $\\mathcal{N}(0.75,0.1^2)$  | $R_\\odot$      |\n",
    "|$m$             | $0.7$      | $\\mathcal{N}(0.70,0.1^2)$  | $M_\\odot$      |\n",
    "|$P_\\mathrm{rot}$| $0.625$    | $\\mathcal{N}(0.625,0.01^2)$| $\\mathrm{days}$|\n",
    "|$P_\\mathrm{orb}$| $1.0$      | $\\mathcal{N}(1.01,0.01^2)$ | $\\mathrm{days}$|\n",
    "|$t_0$           | $0.15$     | $\\mathcal{N}(0.15,0.001^2)$| $\\mathrm{days}$|\n",
    "|$i$             | $80.0$     | $\\mathcal{N}(80.0,5.0^2)$  | $\\mathrm{deg}$ |\n",
    "|$e$             | $0.0$      | $0.0$                      | $-$            |\n",
    "|$\\Omega$        | $0.0$      | $0.0$                      | $\\mathrm{deg}$ |\n",
    "|$u_1$           | $0.20$     | $\\mathrm{Kipping}$         | $-$            |\n",
    "|$u_2$           | $0.05$     | $\\mathrm{Kipping}$         | $-$            |\n",
    "\n",
    "Above, $\\mathcal{N}$ denotes a 1-d normal prior with a given mean and variance, and $\\mathrm{Kipping}$ denotes the prior introduced in [Kipping (2013)](https://arxiv.org/abs/1308.0009) for uninformative sampling over limb darkening coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "\n",
    "    PositiveNormal = pm.Bound(pm.Normal, lower=0.0)\n",
    "\n",
    "    # Primary\n",
    "    A_inc = 80  # pm.Normal(\"A_inc\", mu=80, sd=5, testval=80)\n",
    "    A_amp = 1.0\n",
    "    A_r = 1.0  # PositiveNormal(\"A_r\", mu=0.95, sd=0.1, testval=0.95)\n",
    "    A_m = 1.0  # PositiveNormal(\"A_m\", mu=1.05, sd=0.1, testval=1.05)\n",
    "    A_prot = 1.25  # PositiveNormal(\"A_prot\", mu=1.25, sd=0.01, testval=1.25)\n",
    "    A_q1 = 0.40  # pm.Uniform(\"A_q1\", lower=0, upper=1, testval=0.1)\n",
    "    A_q2 = 0.25  # pm.Uniform(\"A_q2\", lower=0, upper=1, testval=0.1)\n",
    "    A_u1 = 2 * tt.sqrt(A_q1) * A_q2\n",
    "    A_u2 = tt.sqrt(A_q1) * (1 - 2 * A_q2)\n",
    "    pm.Deterministic(\"A_u1\", A_u1)\n",
    "    pm.Deterministic(\"A_u2\", A_u2)\n",
    "    pri = starry.Primary(\n",
    "        starry.Map(ydeg=A[\"ydeg\"], udeg=A[\"udeg\"], inc=A_inc, amp=A_amp),\n",
    "        r=A_r,\n",
    "        m=A_m,\n",
    "        prot=A_prot,\n",
    "    )\n",
    "    pri.map[1] = A_u1\n",
    "    pri.map[2] = A_u2\n",
    "\n",
    "    # Secondary\n",
    "    B_inc = 80  # pm.Normal(\"B_inc\", mu=80, sd=5, testval=80)\n",
    "    B_amp = 0.1\n",
    "    B_r = pm.Uniform(\n",
    "        \"B_r\", lower=0.1, upper=1.0\n",
    "    )  # 0.7 #PositiveNormal(\"B_r\", mu=0.75, sd=0.1, testval=0.75)\n",
    "    B_m = 0.7  # PositiveNormal(\"B_m\", mu=0.70, sd=0.1, testval=0.70)\n",
    "    B_prot = 0.625  # PositiveNormal(\"B_prot\", mu=0.625, sd=0.01, testval=0.625)\n",
    "    B_porb = 1.0  # PositiveNormal(\"B_porb\", mu=1.01, sd=0.01, testval=1.01)\n",
    "    B_t0 = 0.15  # pm.Normal(\"B_t0\", mu=0.15, sd=0.001, testval=0.15)\n",
    "    B_q1 = 0.20  # pm.Uniform(\"B_q1\", lower=0, upper=1, testval=0.1)\n",
    "    B_q2 = 0.05  # pm.Uniform(\"B_q2\", lower=0, upper=1, testval=0.1)\n",
    "    B_u1 = 2 * tt.sqrt(B_q1) * B_q2\n",
    "    B_u2 = tt.sqrt(B_q1) * (1 - 2 * B_q2)\n",
    "    pm.Deterministic(\"B_u1\", B_u1)\n",
    "    pm.Deterministic(\"B_u2\", B_u2)\n",
    "    sec = starry.Secondary(\n",
    "        starry.Map(ydeg=B[\"ydeg\"], udeg=B[\"udeg\"], inc=B_inc, amp=B_amp),\n",
    "        r=B_r,\n",
    "        m=B_m,\n",
    "        porb=B_porb,\n",
    "        prot=B_prot,\n",
    "        t0=B_t0,\n",
    "        inc=B_inc,\n",
    "    )\n",
    "    sec.map[1] = B_u1\n",
    "    sec.map[2] = B_u2\n",
    "\n",
    "    # System\n",
    "    sys = starry.System(pri, sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's declare our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    sys.set_data(flux, C=sigma ** 2)\n",
    "    pri.map.set_prior(L=1e-2)\n",
    "    sec.map.set_prior(L=1e-2)\n",
    "    pm.Potential(\"marginal\", sys.lnlike(t=t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've specified the model, it's a good idea to run a quick gradient descent to find the MAP (maximum a posteriori) solution. This will give us a decent starting point for the inference problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with model:\n",
    "    map_soln = xo.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    MAP = xo.eval_in_model(sys.solve(t=t)[0], point=map_soln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = starry.Map(ydeg=A[\"ydeg\"])\n",
    "map.inc = A[\"inc\"]  # map_soln[\"A_inc\"]\n",
    "map[1:, :] = MAP[0]\n",
    "map.show(theta=np.linspace(0, 360, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = starry.Map(ydeg=B[\"ydeg\"])\n",
    "map.inc = B[\"inc\"]  # map_soln[\"B_inc\"]\n",
    "map[1:, :] = MAP[1]\n",
    "map.show(theta=np.linspace(0, 360, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "with model:\n",
    "    trace = pm.sample(\n",
    "        tune=250,\n",
    "        draws=500,\n",
    "        start=map_soln,\n",
    "        chains=4,\n",
    "        cores=1,\n",
    "        step=xo.get_dense_nuts_step(target_accept=0.9),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varnames = [\"B_r\"]\n",
    "display(pm.summary(trace, varnames=varnames).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corner(trace[\"B_r\"], truths=[B[\"r\"]]);"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "nbsphinx_execute": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
