{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we discuss how to linearly solve for the posterior over spherical harmonic coefficients of a map given a light curve. This is similar to what we did in the [Eclipsing Binary](EclipsingBinary_Linear.ipynb) notebook. The idea is to take advantage of the linearity of the `starry` solution to analytically compute the posterior over maps consistent with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "%run notebook_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import starry\n",
    "\n",
    "np.random.seed(12)\n",
    "starry.config.lazy = False\n",
    "starry.config.quiet = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to demonstrate the linear solve feature using a map in reflected light, since the presence of a day/night terminator breaks many degeneracies and makes the mapping problem [much less ill-posed](NullSpace.ipynb). Let's begin by instantiating a reflected light map of the Earth. We'll give it the same obliquity as the Earth and observe it at an inclination of 60 degrees. We'll also give it an amplitude of 1.3: this is the value that will scale the light curve (and which we will infer below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = starry.Map(ydeg=10, reflected=True)\n",
    "map.load(\"earth\")\n",
    "map.amp = 1.3\n",
    "map.obl = 23.5\n",
    "map.inc = 60\n",
    "map.show(projection=\"rect\", illuminate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate a dataset. We'll assume we have 10,000 observations over the course of a full orbit of the planet. We further take the planet's rotation period to be one-tenth of its orbital period. This will give us good coverage during all seasons, maximizing the amount of data we have for all the different regions of the planet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the planet rotate 10 times over one full orbit\n",
    "npts = 10000\n",
    "nrot = 10\n",
    "time = np.linspace(0, 1, npts)\n",
    "theta = np.linspace(0, 360 * nrot, npts)\n",
    "\n",
    "# Position of the star relative to the planet in the orbital plane\n",
    "t = np.reshape(time, (1, -1))\n",
    "p = np.vstack((np.cos(2 * np.pi * t), np.sin(2 * np.pi * t), 0 * t))\n",
    "\n",
    "# Rotate to an observer inclination of 60 degrees\n",
    "ci = np.cos(map.inc * np.pi / 180)\n",
    "si = np.sin(map.inc * np.pi / 180)\n",
    "R = np.array([[1, 0, 0], [0, ci, -si], [0, si, ci]])\n",
    "xs, ys, zs = R.dot(p)\n",
    "\n",
    "# Keywords to the `flux` method\n",
    "kwargs = dict(theta=theta, xs=xs, ys=ys, zs=zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the flux\n",
    "flux0 = map.flux(**kwargs)\n",
    "sigma = 0.005\n",
    "flux = flux0 + sigma * np.random.randn(npts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 4))\n",
    "ax.plot(time, flux)\n",
    "ax.set_xlabel(\"orbital phase\", fontsize=18)\n",
    "ax.set_ylabel(\"flux\", fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the fun part. Let's instantiate a new map so we can do inference on this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = starry.Map(ydeg=10, reflected=True)\n",
    "map.obl = 23.5\n",
    "map.inc = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set the data vector (the flux and the covariance matrix):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map.set_data(flux, C=sigma ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the prior, which is also described as a multivariate gaussian with a mean $\\mu$ and covariance $\\Lambda$. This is the prior on the **amplitude-weighted** spherical harmonic coefficients. In other words, if $\\alpha$ is the map amplitude (``map.amp``) and $y$ is the vector of spherical harmonic coefficients (``map.y``), we are placing a prior on the quantity $x \\equiv \\alpha y$. While this may be confusing at first, recall that the coefficient of the $Y_{0,0}$ harmonic is **fixed at unity** in ``starry``, so we can't really solve for it. But we *can* solve for all elements of the vector $x$. Once we have the posterior for $x$, we can easily obtain both the amplitude (equal to $x_0$) and the spherical harmonic coefficient vector (equal to $x / x_0$). This allows us to simultaneously obtain both the amplitude and the coefficients using a single efficient linear solve.\n",
    "\n",
    "For the mean $\\mu$, we'll set the first coefficient to unity (since we expect $\\alpha$ to be distributed about one, if the light curve is properly normalized) and all the others to zero (since our prior is isotropic and we want to enforce some regularization to keep the coefficients small).\n",
    "\n",
    "For the covariance $\\Lambda$ (``L`` in the code), we'll make it a diagonal matrix. The first diagonal entry is the prior variance on the amplitude of the map, and we'll set that to $10^{-1}$. The remaining entries are the prior variance on the amplitude-weighted coefficients. We'll pick something small---$5 \\times 10^{-4}$---to keep things well regularized. In practice, this prior is related to our beliefs about the angular power spectrum of the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.empty(map.Ny)\n",
    "mu[0] = 1\n",
    "mu[1:] = 0\n",
    "L = np.empty(map.Ny)\n",
    "L[0] = 1e-1\n",
    "L[1:] = 5e-4\n",
    "map.set_prior(L=L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we call `solve`, passing in the `kwargs` from before. In this case, we're assuming we know the orbital information exactly. (When this is not the case, we need to do sampling for the orbital parameters; we cover this in more detail in the **Eclipsing Binary** tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x, cho_cov = map.solve(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values returned are the posterior mean of the amplitude-weighted spherical harmonic coefficients `mu` and the Cholesky factorization of the posterior covariance matrix `cho_cov`. To view our *mean* map, we can do what we described above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map.amp = x[0]\n",
    "map[1:, :] = x[1:] / x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map.show(projection=\"rect\", illuminate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map.amp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that we recovered the correct amplitude, with small error). We can also draw a random sample from the posterior (which automatically sets the map amplitude and coefficients) by calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map.show(projection=\"rect\", illuminate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map.amp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that we got a good fit to the data from this random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 4))\n",
    "ax.plot(time, flux)\n",
    "plt.plot(time, map.flux(**kwargs))\n",
    "ax.set_xlabel(\"Orbital phase\", fontsize=18)\n",
    "ax.set_ylabel(\"Normalized flux\", fontsize=18);"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
